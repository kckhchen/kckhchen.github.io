---
layout: post
date: 2025-01-28
math: "true"
title: 理解樣本變異數與自由度（三）：樣本變異數校正背後的數學
categories: [zh]
---

在這篇文章中，我會用更嚴謹的方法告訴你，為何樣本變異數的分母必須是 n-1，以及這在計算上會有什麼實際影響。我現在會假設看到這裡的你有一點統計底子，所以會跳過一些常見的統計定理和計算過程。

為何樣本變異數的分母必須是 n-1？因為分母是 n-1 的樣本變異數才會是母體變異數的不偏估計式（unbiased estimator）；相反地，若將分母寫成 n，我們會得到母體變異數的偏誤估計式（biased estimator）。

我們先對不偏性簡單做說明。

## 不偏估計式

在統計上用來衡量一個估計式表現有多好的方式有很多種，其中一種就是不偏性（unbiasedness）。擁有不偏性的估計式就叫做不偏估計式。不偏性是一種很直覺的良好性質：我們希望我們估算出來的數值，「平均而言」會落在真正的參數上。也就是不偏估計式的期望值，要等於真正的參數。

\\[
\mathbf{E}\left[\hat{\theta}(X)\right] = \theta
\\]


反之，如果估算出來的數值平均而言會有偏差，我們就將這種估計式稱之為偏誤估計式（biased estimator）。

### 母體平均值的不偏估計式

不偏估計式的最佳實例就是樣本平均值 X_bar，它是母體平均值 μ 的不偏估計式。

\\[
\mathbb{E}\left[ \bar{X} \right] = \mathbb{E}\left[ \frac{1}{n} \sum_{i=1}^{n} X_{i} \right] = \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} X_{i} \right] = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E} \left[ X_{1} \right] = \frac{1}{n} n\mu = \mu
\\]

上方的證明假設 Xi 為母體平均值為 μ 的 iid 分佈，因此每一個 Xi 的期望值都是 μ。另外我們也用上了期望值線性性質（因此加總符號可以移動到期望值外）。因此我們發現平均而言，樣本平均值會落在母體平均值上，因此平均而言這估計是準確的（抱歉有點饒口）。

### 未修正樣本變異數的偏誤

接著我們來看如果沒有對樣本變異數進行修正，也就是將 n 而非 n-1 作為分母，會發生什麼事。我們先來一個常見的統計公式：


\\[
\sum_{i=1}^{n} (X_{i} - \bar{X})^{2} = \sum_{i=1}^{n} X_{i}^{2} - n\bar{X}^{2}
\\]


左右同除以 n 就會得到：


\\[
\mathbb{Var} \left[ X \right]  = \mathbb{E} \left[ X^{2} \right] - \mathbb{E} \left[ X \right] ^{2}
\\]


將上式重新移項會得到我們下面要用到的結果：


\\[
\mathbb{E} \left[ X^{2} \right] = \mathbb{Var} \left[ X \right] +  \mathbb{E} \left[ X \right] ^{2}
\\]



詳細證明不難，我就不贅述了。現在我們可以用上這條公式，推導出未修正樣本變異數的期望值：


\begin{align}
\mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (X_{i} - \bar{X})^{2} \right] 
&= \frac{1}{n} \mathbb{E} \left[ \sum_{i=1}^{n} X_{i}^{2} - n\bar{X}^{2} \right]  \\\\\\\\
&= \frac{1}{n} \left( \sum_{i=1}^{n} \mathbb{E} \left[ X_{i}^{2} \right]  - n\mathbb{E} \left[ \bar{X}^{2} \right]  \right) \\\\\\\\
&= \frac{1}{n}\left( n(\sigma^{2} + \mu^{2}) - n \left( \frac{\sigma^{2}}{n} + \mu^{2} \right)  \right) \\\\\\\\
&= \sigma^{2} + \mu^{2} - \frac{\sigma^{2}}{n} - \mu^{2} \\\\\\\\
&= \frac{n-1}{n} \sigma^{2}
\end{align}


我們意外的發現，若使用分母 n，樣本變異數的期望值竟然不是母體變異數，也就是說，分母為 n 的樣本變異數是母體變異數的一個偏誤估計式！

也就是說，我們在使用分母為 n 的樣本變異數時，平均而言，這個估計值不會落在 σ² 上，而會歪歪斜斜地落在 σ² 的 (n-1) / n 倍的位置。因此，使用這個估計式，我們將會稍微低估母體的變異數。

另外我們也觀察到，偏誤的量是 n / (n-1)，也就是說，我們只要把分母的 n 改為 n-1，估計上就沒有偏誤了。這正好就是樣本變異數是 n-1 的原因：分母為 n-1 的修正版本樣本變異數，會是母體變異數的不偏估計式。這點可以簡單修改上面的算是快速驗證，我就不囉唆重新寫一遍了。

這個結果解釋了上一篇當中，提到為何變異數的校正量正好是 n-1 了。這個校正方法在統計上稱為[貝索校正（Bessel's correction)](https://en.wikipedia.org/wiki/Bessel%27s_correction)。

偏誤固然是一個不好的性質，但真的有那麼嚴重嗎？

### 偏誤，有關係嗎？

簡單來說，當 n 很大很大的時候，偏誤其實沒有很大的影響，這對應到了我們上一篇所提到的直覺。

數學上來說，即便我們知道未修正變異數公式的期望值是有偏差的 σ² (n-1) / n，但是當 n 很大的時候， (n-1) / n 會趨近於 1，我們的期望值也會趨近真正的變異數：

\\[
\mathbb{E} \left[ \frac{1}{n} \sum_{i=1}^{n} (X_{i} - \bar{X})^{2} \right] = \frac{n-1}{n} \sigma^{2} \to \sigma^{2} \quad \text{as} \quad n \to \infty
\\]


當 n 越大，誤差越小，而當 n 趨近於無限大時，幾乎就沒有偏誤了。我們稱這種狀況為「漸進不偏（asymptotically unbiased）」，雖然不像不偏性這樣美好，但也是很棒的性質了。

因此，未修正的樣本變異數雖然是母體變異數的偏誤估計式，但卻是它的漸進不偏估計式。

另外，衡量估計式表現的另一個方法是看估計的一致性（consistency）。如果我們從一致性來看的話，無論是有沒有修正過的樣本變異數，都是母體變異數的一致估計式，兩者在這個賽道上不分軒輊。

### 所以校正後的變異數完美了嗎？

現在我們知道貝索校正後的樣本變異數是母體變異數的不偏估計式，這固然是個好消息，但這代表現在的樣本變異數就是完美的選擇了嗎？答案是不。

首先，雖然校正後的樣本變異數是母體變異數的不偏估計式，但是**校正後的樣本標準差卻不是母體標準差的不偏估計式**（雖然沒校正的也不是）。我們都知道標準差是變異數的開根號，而開根號本質是上是一個凹函數。根據詹森不等式（Jensen's Inequality）：

\\[
\mathbb{E} \left[ \sqrt{ S^{2} } \right] \leq \sqrt{ \mathbb{E} \left[ S^{2} \right] } = \sqrt{ \sigma^{2} } = \sigma
\\]


因此校正後的樣本標準差低估了母體的標準差，是一個偏誤估計式。

另外，在校正後，我們做的犧牲是讓這個估計式擁有較高的均方誤（Mean Squared Error, MSE）。均方誤的公式為

\\[
MSE = \mathbb{E} \left[ (\hat{\theta}(X) - \theta)^{2} \right] 
\\]

我們也可以將其寫成

\\[
MSE = \mathbb{E} \left[ (\hat{\theta}(X) - \theta)^{2} \right] = \mathbb{Var} \left[ \hat{\theta} \right]  + Bias(\hat{\theta})^{2}
\\]

也就是說，我們可以將均方誤理解為估計式的變異數和偏誤的平方相加。這意味著雖然校正過後的變異數降低了偏誤，換來的代價卻是增加了它的變異數（對，變異數估計值的變異數）。並且，校正後的樣本變異數擁有的均方誤，比起校正前的還要來得高。

這些都顯示校正後的樣本變異數不是完美的存在，也不是唯一的依歸。我們可以依照對估計的需求，選擇我們當下需要的估計式。有時未校正的樣本變異數可能會在某些表現上，更勝校正過後的一籌。

在統計當中，這是我們天天都要面對的實際問題：通常在降低估計偏誤的同時，我們換來的是更高的變異（可以想成更不穩定的估計結果）。如何在這之中求取最好的平衡，是統計這門科學背後的藝術。

## 文章總結

1. 分母為 n 的樣本變異數是母體變異數的偏誤估計式。
2. 透過將分母調整為 n-1，我們就可以得到母體變異數的不偏估計式，這樣的修正手法稱為貝索校正。
3. 使用未校正的樣本變異數，在樣本數 n 很大時，偏誤會趨近於 0。
4. 校正後的樣本變異數雖然是母體變異數的不偏估計式，但樣本標準差卻不是母體標準差的不偏估計式。
5. 校正過後我們付出的代價是引來更高的均方誤，更精確來說，我們增加了估計的變異程度。
6. 估計式的變異程度和偏誤是統計中常常碰到的權衡問題。

## 結語

希望這系列文章一路看下來，有讓你更理解這個從許多人初學統計時，就不免碰上卻一直無法好好了解的題目。如果對於這系列文章有任何指教或建議都歡迎留言，我非常樂意討論並修改文章。若有任何問題，也歡迎提出，我會盡我所能地給出你滿意的答案。

#writing #stats

{% include mathjax.html %}